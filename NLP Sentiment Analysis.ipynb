{"cells":[{"cell_type":"markdown","metadata":{"id":"typeL4Gv8CRO"},"source":["### Sentiment Analysis\n","* Sentiment analysis involves determining the sentiment of text.\n","* In this lab, you will use a hotel review data set that includes reviews and a rating \n"," * There are other features that you can ignore, unless you want to use them to improve results\n","* Your goal is to train a model that can predict the number of stars based on the text\n","* This is the last programming assignment. We will use similar cleaning and discovery techniques as other assignments\n"," * ... except we need to add the fun of stop words, stemming / lemmatizing and similar exciting topics.\n","* Dont forget to save this as a copy in your Google Colab environment\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y6kVJIdAH_he"},"source":["* **Student Name:** TU HOANG"]},{"cell_type":"markdown","metadata":{"id":"tJwqnYR6Isep"},"source":["### Get the data\n","* Either download the data and store it in your drive or use the Kaggle API to obtain the data from\n"," * https://www.kaggle.com/datasets/datafiniti/hotel-reviews"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"EFfOL3fX79AX"},"outputs":[],"source":["import pandas as pd\n","import seaborn as sns\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import MinMaxScaler\n","from tensorflow.keras import layers\n","from tensorflow.keras.models import Sequential\n","tf.random.set_seed(1)"]},{"cell_type":"markdown","metadata":{"id":"cZPC5CpfIxgp"},"source":["### Explore and Clean the Data"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Read and set up the data\n","df1 = pd.read_csv(\"Datafiniti_Hotel_Reviews.csv\")\n","df2 = pd.read_csv(\"Datafiniti_Hotel_Reviews_Jun19.csv\").drop('reviews.dateAdded', axis=1)\n","df_review = pd.concat([df1, df2], axis=0)\n","df_review = df_review[['reviews.text','reviews.rating']]"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Drop any empty rows\n","df_review.dropna(inplace=True)"]},{"cell_type":"markdown","metadata":{},"source":["Using only two columns which are \"review.text\" and \"review.rating\" as string input and labels"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>reviews.text</th>\n","      <th>reviews.rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Our experience at Rancho Valencia was absolute...</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Amazing place. Everyone was extremely warm and...</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>We booked a 3 night stay at Rancho Valencia to...</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Currently in bed writing this for the past hr ...</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I live in Md and the Aloft is my Home away fro...</td>\n","      <td>5.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                        reviews.text  reviews.rating\n","0  Our experience at Rancho Valencia was absolute...             5.0\n","1  Amazing place. Everyone was extremely warm and...             5.0\n","2  We booked a 3 night stay at Rancho Valencia to...             5.0\n","3  Currently in bed writing this for the past hr ...             2.0\n","4  I live in Md and the Aloft is my Home away fro...             5.0"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["df_review.head()"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Cast the reviews.rating column to Integer\n","df_review = df_review.astype({'reviews.rating': 'int32'})"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["df_review[\"rating\"] = df_review[\"reviews.rating\"].apply(lambda x: 2 if 4 < x <= 5 else 1 if 2 < x <= 4 else 0)"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>reviews.text</th>\n","      <th>reviews.rating</th>\n","      <th>rating</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Our experience at Rancho Valencia was absolute...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Amazing place. Everyone was extremely warm and...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>We booked a 3 night stay at Rancho Valencia to...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Currently in bed writing this for the past hr ...</td>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>I live in Md and the Aloft is my Home away fro...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9995</th>\n","      <td>My friends and I took a trip to Hampton for th...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>from check in to departure, staff is friendly,...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>This Hampton is located on a quiet street acro...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>Awesome wings (my favorite was garlic parmesan...</td>\n","      <td>5</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>Clean facility just off freeway ..... staff fr...</td>\n","      <td>4</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>19999 rows Ã— 3 columns</p>\n","</div>"],"text/plain":["                                           reviews.text  reviews.rating  \\\n","0     Our experience at Rancho Valencia was absolute...               5   \n","1     Amazing place. Everyone was extremely warm and...               5   \n","2     We booked a 3 night stay at Rancho Valencia to...               5   \n","3     Currently in bed writing this for the past hr ...               2   \n","4     I live in Md and the Aloft is my Home away fro...               5   \n","...                                                 ...             ...   \n","9995  My friends and I took a trip to Hampton for th...               4   \n","9996  from check in to departure, staff is friendly,...               5   \n","9997  This Hampton is located on a quiet street acro...               5   \n","9998  Awesome wings (my favorite was garlic parmesan...               5   \n","9999  Clean facility just off freeway ..... staff fr...               4   \n","\n","      rating  \n","0          2  \n","1          2  \n","2          2  \n","3          0  \n","4          2  \n","...      ...  \n","9995       1  \n","9996       2  \n","9997       2  \n","9998       2  \n","9999       1  \n","\n","[19999 rows x 3 columns]"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["df_review"]},{"cell_type":"markdown","metadata":{},"source":["- The dataframe that we used to feed the model contains two columns which are text and rating for all the reviews.\n","\n","\n","- Remove all the rows which are missing.\n","\n","\n","- Grouping the rating into 3 categories: [1,2) is '0', [2,4) is '1', and [4,5] is '2'."]},{"cell_type":"markdown","metadata":{"id":"tptdq4z_z_zr"},"source":["### Train the Model\n","* Train the model using 90% of the data\n","* You may choose whichever model technique you choose"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"BNRXiyZU0RZC"},"outputs":[],"source":["# Split the data into test and train data respectively with 10% for test (labels)\n","train_sentences, val_sentences, train_labels, val_labels = train_test_split(df_review[\"reviews.text\"].to_numpy(), df_review[\"rating\"].to_numpy(), test_size=0.1, random_state=42)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# Setup text vectorization\n","text_vectorizer = layers.TextVectorization(max_tokens=20000, output_sequence_length=90)\n","# Fit the text vectorizer to the training text\n","text_vectorizer.adapt(train_sentences)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# Creating an Embedding using an Embedding Layer\n","embedding = layers.Embedding(input_dim=20001, output_dim=512, input_length=90, mask_zero=True)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# Create the LSTM model\n","LSTM_model = Sequential()\n","LSTM_model.add(layers.Input(shape=(1,), dtype=\"string\"))\n","LSTM_model.add(text_vectorizer)\n","LSTM_model.add(embedding)\n","LSTM_model.add(layers.LSTM(256))\n","LSTM_model.add(layers.Dense(64, activation='relu'))\n","LSTM_model.add(layers.Dense(3, activation='softmax'))"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Model: \"sequential_3\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," text_vectorization_1 (TextV  (None, 90)               0         \n"," ectorization)                                                   \n","                                                                 \n"," embedding_1 (Embedding)     (None, 90, 512)           10240512  \n","                                                                 \n"," lstm_4 (LSTM)               (None, 256)               787456    \n","                                                                 \n"," dense_4 (Dense)             (None, 64)                16448     \n","                                                                 \n"," dense_5 (Dense)             (None, 3)                 195       \n","                                                                 \n","=================================================================\n","Total params: 11,044,611\n","Trainable params: 11,044,611\n","Non-trainable params: 0\n","_________________________________________________________________\n"]}],"source":["LSTM_model.summary()"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["LSTM_model.compile(optimizer=tf.keras.optimizers.Adam(),\n","                   loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n","                   metrics=[\"sparse_categorical_accuracy\"])"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/6\n","563/563 [==============================] - 24s 36ms/step - loss: 0.1067 - sparse_categorical_accuracy: 0.9584 - val_loss: 1.5295 - val_sparse_categorical_accuracy: 0.6345\n","Epoch 2/6\n","563/563 [==============================] - 18s 33ms/step - loss: 0.0771 - sparse_categorical_accuracy: 0.9714 - val_loss: 1.7813 - val_sparse_categorical_accuracy: 0.6305\n","Epoch 3/6\n","563/563 [==============================] - 19s 34ms/step - loss: 0.0435 - sparse_categorical_accuracy: 0.9839 - val_loss: 2.2108 - val_sparse_categorical_accuracy: 0.6335\n","Epoch 4/6\n","563/563 [==============================] - 20s 35ms/step - loss: 0.0358 - sparse_categorical_accuracy: 0.9862 - val_loss: 2.1951 - val_sparse_categorical_accuracy: 0.6360\n","Epoch 5/6\n","563/563 [==============================] - 19s 34ms/step - loss: 0.0296 - sparse_categorical_accuracy: 0.9899 - val_loss: 2.3912 - val_sparse_categorical_accuracy: 0.6320\n","Epoch 6/6\n","563/563 [==============================] - 19s 33ms/step - loss: 0.0268 - sparse_categorical_accuracy: 0.9902 - val_loss: 2.5988 - val_sparse_categorical_accuracy: 0.6225\n"]}],"source":["history = LSTM_model.fit(train_sentences, train_labels, epochs=6, validation_data=(val_sentences, val_labels))"]},{"cell_type":"markdown","metadata":{"id":"SgZ8Xs890Rtj"},"source":["### Test the Model \n","* Test the model using the remaining 10% of the data\n","* The testing results will depend on the model you use\n"," * If the rating is evaluated as a number, you need to look at values such as mean square error\n"," * If you are using categories, then you can use accuracy, but you may want to collapse the categories from 1 to 5 to 3 categories such as bad, neutral, and good."]},{"cell_type":"code","execution_count":39,"metadata":{"id":"PfbYZg_L0Yi0"},"outputs":[],"source":["from sklearn.metrics import accuracy_score"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["63/63 [==============================] - 1s 9ms/step\n"]}],"source":["# Getting predicting labels\n","y_preds = tf.squeeze(tf.round(LSTM_model.predict(val_sentences)))\n","y_preds = np.argmax(y_preds, 1)"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["0.6305"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["# Calculating the accuracy with the validation data\n","accuracy_score(val_labels, y_preds)"]},{"cell_type":"markdown","metadata":{"id":"OaXo8jUy0WUS"},"source":["### Provide an explanation of your model and results"]},{"cell_type":"markdown","metadata":{"id":"SfLL61850b1-"},"source":["* The data is splitting into 90% train and 10% test.\n","* The model consists of a vector tonkenizer layer, an embedding layer, a LSTM layer, a Dense layer, and an output layer.\n","* The maximum vocabulary is 20000 and the maximum tokens is 90.\n","* Output labels are 0, 1, 2 which represent 0-2 rating, 2-4 rating and 4-5 rating respectively from the original ratings criteria.\n","* Optimizer function is Adam, and loss function is sparse categorical cross-entropy.\n","* Metric for accuracy is sparse categorical accuracy.\n","  \n","* The result is not as good as I expected - the final accuracy is around 63%.\n","* The current problem of model is that the better it fits the train data, the higher the loss of validation data.\n","* It highly suggests over-fitting for this model."]},{"cell_type":"markdown","metadata":{"id":"Rz2jXJhO4sPB"},"source":["### Discuss techniques you could use to improve your model if you had more time"]},{"cell_type":"markdown","metadata":{"id":"rLr2jlic4wJU"},"source":["* To reduce over-fitting, we could implement early stopping and drop out additionally.\n","\n","* Preprocessing could use more help such as handling stopwords, lemming.\n","  \n","* The model itself could be improved upon by using different embedding method such as Word2Vec, transfer learning.\n","* The layers can be extended further with stacked RNN layers.\n","* Different techniques also possible such as GRU, bidirectional."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyO8rzzmAuGIvFXITHuKhZif","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"},"vscode":{"interpreter":{"hash":"c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"}}},"nbformat":4,"nbformat_minor":0}
